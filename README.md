# Donâ€™t Touch The Art! - Gesture Controlled Musical Instrument

Abstract

Hand gestures are a natural and intuitive way to interact with machines. This project blends hardware and software components to create a multi-sensory, engaging experience for the viewer. The final product is an interactive musical instrument consisting of six sound rods placed in a circular formation. In the centre, is a hammer-like attachment that rotates and strikes the sound rods. The software component applies a sequential machine learning model to detect and recognize hand gestures passed to it via a video feed. Libraries used include OpenCV and CVZone. The HandTrackingModule from CVZone marks skeleton-based landmarks which helps increase precision in classification. The hardware circuit is built using an Arduino UNO and A4988 motor driver. The motor used is a NEMA 17 stepper motor. The classified gesture defines the movement pattern in the stepper motor which rotates the hammer attachment and strikes the sound rods, adding a real-time visual and auditory feedback to the viewer.

Tags: Gesture Recognition, Computer Vision, Hardware programming, Microcontroller, Audio Synthesis, Sound Generation

Full report available
